{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "inK2MxwM9X4O"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "image_paths = [\n",
        "'/home/Dataset/UTRNet_data/Scene9/RGB_image/2013-10-03.tiff',\n",
        "'/home/Dataset/UTRNet_data/Scene9/RGB_image/2014-08-19.tiff',\n",
        "'/home/Dataset/UTRNet_data/Scene9/RGB_image/2015-05-18.tiff',\n",
        "'/home/Dataset/UTRNet_data/Scene9/RGB_image/2017-07-10.tiff',\n",
        "'/home/Dataset/UTRNet_data/Scene9/RGB_image/2017-09-28.tiff',\n",
        "'/home/Dataset/UTRNet_data/Scene9/RGB_image/2018-10-01.tiff',\n",
        "'/home/Dataset/UTRNet_data/Scene9/RGB_image/2019-09-18.tiff',\n",
        "'/home/Dataset/UTRNet_data/Scene9/RGB_image/2020-09-20.tiff',\n",
        "'/home/Dataset/UTRNet_data/Scene9/RGB_image/2021-05-02.tiff',\n",
        "'/home/Dataset/UTRNet_data/Scene9/RGB_image/2021-06-19.tiff'\n",
        "]\n",
        "\n",
        "#loading the images and stacking them sequentially\n",
        "def load_images(image_paths):\n",
        "    images = []\n",
        "    for path in image_paths:\n",
        "        image = cv2.imread(path)\n",
        "        images.append(image)\n",
        "\n",
        "    stacked_images = np.stack(images, axis=-1)\n",
        "    return stacked_images\n",
        "\n",
        "# This function applies Fast Fourier Transformation and low-frequency masking\n",
        "def apply_frequency_mask(image, radius=50):\n",
        "    original_dft = np.fft.fftshift(np.fft.fft2(image, axes=(0, 1)))\n",
        "    magnitude_spectrum = np.abs(original_dft)\n",
        "\n",
        "    rows, cols = image.shape[:2]\n",
        "    crow, ccol = rows // 2, cols // 2\n",
        "\n",
        "    low_freq_mask = np.zeros((rows, cols), np.uint8)\n",
        "    cv2.circle(low_freq_mask, (ccol, crow), radius, 1, thickness=-1)\n",
        "\n",
        "    low_freq_magnitude = magnitude_spectrum * low_freq_mask\n",
        "\n",
        "    # Reconstruct the image using inverse FFT\n",
        "    reconstructed_image = reconstruct_image(original_dft, low_freq_magnitude)\n",
        "\n",
        "    return np.clip(reconstructed_image, 0, 255).astype(np.uint8)\n",
        "\n",
        "# This function reconstruct the image using inverse FFT\n",
        "def reconstruct_image(original_dft, masked_magnitude):\n",
        "    phase = np.angle(original_dft)\n",
        "    combined_spectrum = masked_magnitude * np.exp(1j * phase)\n",
        "    inverse_shift = np.fft.ifftshift(combined_spectrum)\n",
        "    reconstructed_image = np.real(np.fft.ifft2(inverse_shift))\n",
        "    return reconstructed_image\n",
        "\n",
        "# This function combines FFT and Masking for all image sequence\n",
        "def apply_mask_sequence(image_sequence, radius=50):\n",
        "    low_freq_sequence = []\n",
        "\n",
        "    for i in range(image_sequence.shape[-1]):\n",
        "        image = image_sequence[..., i]\n",
        "        if image.ndim == 3:\n",
        "            low_freq_img = []\n",
        "            for ch in range(image.shape[2]):\n",
        "                lf_img = apply_frequency_mask(image[:, :, ch], radius)\n",
        "                low_freq_img.append(lf_img)\n",
        "\n",
        "            low_freq_img = np.stack(low_freq_img, axis=-1)\n",
        "        else:\n",
        "            low_freq_img = apply_frequency_mask(image, radius)\n",
        "\n",
        "        low_freq_sequence.append(low_freq_img)\n",
        "\n",
        "    low_freq_sequence = np.stack(low_freq_sequence, axis=-1)\n",
        "\n",
        "    return low_freq_sequence\n",
        "\n",
        "stacked_images = load_images(image_paths)\n",
        "\n",
        "low_freq_sequence = apply_mask_sequence(stacked_images)\n",
        "\n",
        "# Normalize images to [0, 1]\n",
        "low_freq_sequence = low_freq_sequence / 255.\n",
        "low_freq_sequence.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "masked_reconstructed_sequence_reshaped = low_freq_sequence.reshape((1, 400, 400, 30))\n",
        "\n",
        "masked_reconstructed_sequence_reshaped.shape"
      ],
      "metadata": {
        "id": "8_YcnvZ_9b3v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, losses, optimizers\n",
        "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score\n",
        "\n",
        "def create_cnn_decoder():\n",
        "    model = models.Sequential([\n",
        "        layers.Input(shape=(None, None, 30)),\n",
        "        layers.Conv2D(64, (3, 3), padding='same'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.ReLU(),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Conv2D(128, (3, 3), padding='same'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.ReLU(),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Conv2D(64, (3, 3), padding='same'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.ReLU(),\n",
        "        layers.Conv2D(1, (3, 3), padding='same', activation='sigmoid')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Define discriminator function for Adversarial Training\n",
        "def create_discriminator():\n",
        "    model = models.Sequential([\n",
        "        layers.Input(shape=(None, None, 1)),\n",
        "        layers.Conv2D(64, (3, 3), strides=(2, 2), padding='same'),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Conv2D(128, (3, 3), strides=(2, 2), padding='same'),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.GlobalAveragePooling2D(),\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Instantiate models\n",
        "decoder = create_cnn_decoder()\n",
        "discriminator = create_discriminator()\n",
        "\n",
        "# Define an exponential decay scheduler for decoder and discriminator\n",
        "#decoder_optimizer = optimizers.Adam(learning_rate=0.0001)\n",
        "#discriminator_optimizer = optimizers.Adam(learning_rate=0.0001)\n",
        "initial_lr = 0.001\n",
        "decay_steps = 1000\n",
        "decay_rate = 0.96\n",
        "\n",
        "lr_schedule = ExponentialDecay(\n",
        "    initial_learning_rate=initial_lr,\n",
        "    decay_steps=decay_steps,\n",
        "    decay_rate=decay_rate,\n",
        "    staircase=True\n",
        ")\n",
        "\n",
        "decoder_optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
        "\n",
        "# Training setup\n",
        "epochs = 500"
      ],
      "metadata": {
        "id": "-TkRHlk79hWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading and processing the ground truth image\n",
        "def load_ground_truth(filepath):\n",
        "    ground_truth = cv2.imread(filepath, cv2.IMREAD_COLOR)\n",
        "    print(f\"Ground truth shape: {ground_truth.shape}\")\n",
        "\n",
        "    ground_truth_rgb = cv2.cvtColor(ground_truth, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    change_lower = np.array([150, 0, 0])\n",
        "    change_upper = np.array([255, 100, 100])\n",
        "\n",
        "    unchange_lower = np.array([150, 150, 0])\n",
        "    unchange_upper = np.array([255, 255, 100])\n",
        "\n",
        "    change_mask = cv2.inRange(ground_truth_rgb, blue_lower, blue_upper)\n",
        "    unchange_mask = cv2.inRange(ground_truth_rgb, green_lower, green_upper)\n",
        "\n",
        "    ground_truth_binary = np.zeros_like(change_mask, dtype=np.uint8)\n",
        "    ground_truth_binary[change_mask > 0] = 1  # Set changed areas to 1\n",
        "    ground_truth_binary[unchange_mask > 0] = 0  # Set unchanged areas to 0\n",
        "\n",
        "    return ground_truth_binary\n",
        "\n",
        "ground_truth_binary = load_ground_truth('/home/Dataset/UTRNet_data/Scene9/Ground_Truth.tiff')\n",
        "\n",
        "ground_truth_binary_resized = cv2.resize(ground_truth_binary,\n",
        "                                         (masked_reconstructed_sequence_reshaped.shape[2],\n",
        "                                          masked_reconstructed_sequence_reshaped.shape[1]))\n",
        "\n",
        "# expand the ground truth dim\n",
        "ground_truth_binary_resized = np.expand_dims(ground_truth_binary_resized, axis=(0, -1))  # Shape: (1, height, width, 1)\n",
        "\n",
        "# binary change map\n",
        "binary_change_map = np.expand_dims(ground_truth_binary, axis=(0, -1))  # Shape: (1, height, width, 1)\n"
      ],
      "metadata": {
        "id": "Z3l6aVjvMoFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Loss Functions with Adversarial Training\n",
        "# Calculate class weights based on the pixel distribution for Binary Cross-Entropy\n",
        "total_pixels = np.prod(ground_truth_binary.shape)\n",
        "change_count = np.sum(ground_truth_binary == 1)\n",
        "unchanged_count = total_pixels - change_count\n",
        "\n",
        "weight_for_changed = (1 / change_count) * (total_pixels / 2.0)\n",
        "weight_for_unchanged = (1 / unchanged_count) * (total_pixels / 2.0)\n",
        "\n",
        "#class_weights = {0: weight_for_unchanged, 1: weight_for_changed}\n",
        "\n",
        "# Focal Loss\n",
        "def focal_loss(y_true, y_pred, alpha=0.25, gamma=2.0):\n",
        "    bce = losses.BinaryCrossentropy()(y_true, y_pred)\n",
        "    bce_exp = tf.exp(-bce)\n",
        "    focal_loss = alpha * (1 - bce_exp) ** gamma * bce\n",
        "    return focal_loss\n",
        "\n",
        "# Weighted Binary Cross-Entropy\n",
        "def weighted_binary_crossentropy(y_true, y_pred, weight_for_unchanged, weight_for_changed):\n",
        "    weights = tf.where(tf.equal(y_true, 1), weight_for_changed, weight_for_unchanged)\n",
        "    return losses.BinaryCrossentropy()(y_true, y_pred, sample_weight=weights)\n",
        "\n",
        "# Contrastive Loss Function\n",
        "def contrastive_loss(y_true, y_pred, margin=1.0):\n",
        "    y_pred = tf.expand_dims(y_pred, axis=-1) if len(y_pred.shape) == 3 else y_pred\n",
        "    squared_pred = tf.reduce_sum(tf.square(y_pred - y_true), axis=-1)\n",
        "    squared_pred = tf.expand_dims(squared_pred, axis=-1)\n",
        "    loss = tf.reduce_mean(y_true * squared_pred + (1 - y_true) * tf.maximum(margin - squared_pred, 0))\n",
        "    return loss\n",
        "\n",
        "# Combined Losses\n",
        "def combined_loss(y_true, y_pred, real_output, fake_output, weight_for_unchanged, weight_for_changed):\n",
        "    # Contrastive loss\n",
        "    con_loss = contrastive_loss(y_true, y_pred)\n",
        "\n",
        "    # Weighted Binary Cross-Entropy Loss\n",
        "    weighted_bce_loss = weighted_binary_crossentropy(y_true, y_pred, weight_for_unchanged, weight_for_changed)\n",
        "\n",
        "    # Focal Loss\n",
        "    focal_loss_value = focal_loss(y_true, y_pred)\n",
        "\n",
        "    # Adversarial Loss (Binary Cross-Entropy for real/fake discriminator predictions)\n",
        "    adv_loss = losses.BinaryCrossentropy()(tf.ones_like(fake_output), fake_output)\n",
        "\n",
        "    # Adjust loss weights\n",
        "    contrastive_loss_weight = 1.0\n",
        "    weighted_bce_loss_weight = 0.5\n",
        "    focal_loss_weight = 0.5\n",
        "    adversarial_loss_weight = 0.5\n",
        "\n",
        "    # Generator/Decoder Loss: Combine all\n",
        "    gen_loss = (contrastive_loss_weight * con_loss) + \\\n",
        "               (weighted_bce_loss_weight * weighted_bce_loss) + \\\n",
        "               (focal_loss_weight * focal_loss_value) + \\\n",
        "               (adversarial_loss_weight * adv_loss)\n",
        "\n",
        "    return gen_loss\n"
      ],
      "metadata": {
        "id": "75K8_01SMYN6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "for epoch in range(epochs):\n",
        "    # Training Discriminator\n",
        "    with tf.GradientTape() as disc_tape:\n",
        "        fake_change_map = decoder(masked_reconstructed_sequence_reshaped, training=True)\n",
        "        real_output = discriminator(binary_change_map, training=True)\n",
        "        fake_output = discriminator(fake_change_map, training=True)\n",
        "\n",
        "        # Discriminator loss\n",
        "        disc_loss = losses.BinaryCrossentropy()(tf.ones_like(real_output), real_output) + \\\n",
        "                    losses.BinaryCrossentropy()(tf.zeros_like(fake_output), fake_output)\n",
        "\n",
        "    grads = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "    discriminator_optimizer.apply_gradients(zip(grads, discriminator.trainable_variables))\n",
        "\n",
        "    # Training Decoder\n",
        "    with tf.GradientTape() as gen_tape:\n",
        "        fake_change_map = decoder(masked_reconstructed_sequence_reshaped, training=True)\n",
        "        fake_output = discriminator(fake_change_map, training=False)\n",
        "\n",
        "        gen_loss = combined_loss(binary_change_map, fake_change_map, real_output, fake_output,\n",
        "                                 weight_for_unchanged, weight_for_changed)\n",
        "\n",
        "    grads = gen_tape.gradient(gen_loss, decoder.trainable_variables)\n",
        "    decoder_optimizer.apply_gradients(zip(grads, decoder.trainable_variables))\n",
        "\n",
        "    # Log training progress\n",
        "    print(f\"Epoch [{epoch+1}/{epochs}], Disc Loss: {disc_loss.numpy():.4f}, Gen Loss: {gen_loss.numpy():.4f}\")\n",
        "\n",
        "# Compare predicted map to ground truth\n",
        "predicted_change_map = decoder.predict(masked_reconstructed_sequence_reshaped)[0].squeeze()\n",
        "\n",
        "predicted_change_map_resized = cv2.resize(predicted_change_map, (ground_truth_binary.shape[1], ground_truth_binary.shape[0]))\n",
        "predicted_change_map_binary = (predicted_change_map_resized > 0.5).astype(np.uint8)\n",
        "\n",
        "\n",
        "# Visualize results\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(predicted_change_map_binary, cmap='gray')\n",
        "plt.title('Predicted Binary Change Map')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(ground_truth_binary, cmap='gray')\n",
        "plt.title('Ground Truth Binary Change Map')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "EaGfilW_N7Jw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate IOU)\n",
        "def calculate_iou(y_true, y_pred):\n",
        "    intersection = np.logical_and(y_true, y_pred).sum()\n",
        "    union = np.logical_or(y_true, y_pred).sum()\n",
        "    iou = intersection / union if union > 0 else 0\n",
        "    return iou\n",
        "\n",
        "# Calculate evaluation metrics using the binary predicted change map\n",
        "accuracy = accuracy_score(ground_truth_binary.flatten(), predicted_change_map_binary.flatten())\n",
        "precision = precision_score(ground_truth_binary.flatten(), predicted_change_map_binary.flatten())\n",
        "recall = recall_score(ground_truth_binary.flatten(), predicted_change_map_binary.flatten())\n",
        "f1 = f1_score(ground_truth_binary.flatten(), predicted_change_map_binary.flatten())\n",
        "kappa = cohen_kappa_score(ground_truth_binary.flatten(), predicted_change_map_binary.flatten())\n",
        "iou = calculate_iou(ground_truth_binary, predicted_change_map_binary)\n",
        "\n",
        "# Print metrics\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(f\"Kappa: {kappa:.4f}\")\n",
        "print(f\"IoU: {iou:.4f}\")\n"
      ],
      "metadata": {
        "id": "FZ2Jmgw3Hj_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1BG6TpwYHj-K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}